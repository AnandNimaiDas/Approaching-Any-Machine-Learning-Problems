{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apporaching categorical variables\n",
    "\n",
    "## What are categorical variables?\n",
    "\n",
    "\n",
    "Categorical variables/features are any feature type can be classified into two major types:\n",
    "\n",
    " • Nominal\n",
    " \n",
    " • Ordinal\n",
    " \n",
    " \n",
    "**Nominal variables** are variables that have two or more categories which do not have any kind of order associated with them. For example, if gender is classified into two groups, i.e. male and female, it can be considered as a nominal variable. \n",
    "\n",
    "\n",
    "**Ordinal variables**, on the other hand, have “levels” or categories with a particular order associated with them. For example, an ordinal categorical variable can be a feature with three different levels: low, medium and high. Order is important. \n",
    "\n",
    "As far as definitions are concerned, we can also categorize categorical variables as **binary**, i.e., a categorical variable with only two categories. Some even talk about a type called **cyclic** for categorical variables. Cyclic variables are present in “cycles” for example, days in a week: Sunday, Monday, Tuesday, Wednesday, Thursday, Friday and Saturday. After Saturday, we have Sunday again. This is a cycle. Another example would be hours in a day if we consider them to be categories. \n",
    "\n",
    "\n",
    "We will be using **cat-in-the-dat** from Categorical Features Encoding Challenge from Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day month  \\\n",
       "0  ...  02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   3.0   \n",
       "1  ...  f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   7.0   \n",
       "2  ...        NaN   3.0          NaN  Freezing     n     P     eN  5.0   9.0   \n",
       "3  ...  f9d456e57   1.0       Novice  Lava Hot     a     C    NaN  3.0   3.0   \n",
       "4  ...  c5361037c   3.0  Grandmaster      Cold     h     C     OZ  5.0  12.0   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset consist of all kinds of categorical variables:\n",
    "* **Nominal**\n",
    "* **Ordinal**\n",
    "* **Cyclical**\n",
    "* **Binary**\n",
    "\n",
    "\n",
    "It is abinary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2bf7351e50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x = \"target\", data  = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~As we know that the target is skewed so we will use **ROC Curve** to evaluate result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, there are: \n",
    "\n",
    "    • Five binary variables \n",
    "    • Ten nominal variables \n",
    "    • Six ordinal variables \n",
    "    • Two cyclic variables \n",
    "    • And a target variable \n",
    "    \n",
    "ord_2 feature consists of six different categories: \n",
    "\n",
    "    • Freezing \n",
    "    • Warm \n",
    "    • Cold \n",
    "    • Boiling Hot \n",
    "    • Hot \n",
    "    • Lava Hot\n",
    "    \n",
    "We have to know that computers do not understand text data and thus, we need to convert these categories to numbers. A simple way of doing this would be to create a dictionary that maps these values to numbers starting from 0 to N-1, where N is the total number of categories in a given feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Freezing\" : 0,\n",
    "    \"Warm\" : 1,\n",
    "    \"Cold\" : 2,\n",
    "    \"Boiling Hot\" : 3,\n",
    "    \"Hot\" : 4,\n",
    "    \"Lava Hot\" : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value count before mapping\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the dataset and convert these categories to numbers easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ :, \"ord_2\"] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value count after mapping\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of encoding of categorical vairbales is known as **Label Encoding** i.e encoding every category as a numerical label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder from scikit-learn.\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "\n",
    "#read the data \n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#fill NaN values in ord_2 column\n",
    "#df.loc[:,\"ord_2\"] = df.ord.fillna(\"NONE\")\n",
    "\n",
    "# initalize LabelEncoder\n",
    "df.loc[:,\"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "#initialize LabelEnocder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "#fit label encoder and transfrom values on ord_2 column\n",
    "# P.S : do not use this directly. fit first, then transform\n",
    "df.loc[:,\"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You first need to fillna from pandas cause LabelEncoder from scikit-learn does not handle NAN values and ord_2 column have NAN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use Label Encoding directly in many tree-based models:**\n",
    "    * Decision trees\n",
    "    * Random forest\n",
    "    * Extra Trees\n",
    "    * Or any kind of boosted trees model\n",
    "         * XGBoost\n",
    "         * GBM\n",
    "         * LightGBM\n",
    "         \n",
    "This type of encoding cannot be used in linear models, SVM or neural network as they expect data to be **normalized**\n",
    "\n",
    "For these types of models, we can binarize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Freezing --> 0 --> 0 0 0 \n",
    "* Warm --> 1 --> 0 0 1 \n",
    "* Cold --> 2 --> 0 1 0\n",
    "* Boiling Hot --> 3 --> 0 1 1 \n",
    "* Hot --> 4 --> 1 0 0 \n",
    "* Lava Hot --> 5 --> 1 0 1 \n",
    "   \n",
    "   \n",
    "\n",
    "This is just converting the categories to numbers and then converting them to their binary representation.\n",
    "\n",
    "We are thus splitting one feature into three (in this case) features (or columns). If we have more categories, we might end up splitting into a lot more columns. \n",
    "\n",
    "It becomes easy to store lots of binarized variables like this if we store them in a **sparse format.** \n",
    "\n",
    "### sparse format\n",
    "A sparse format is nothing but a representation or way of storing data in memory in which you do not store all the values but only the values that matter. In the case of binary variables described above, all that matters is where we have ones (1s). It’s difficult to imagine a format like this but should become clear with an example. Let’s assume that we are provided with only one feature in the dataframe above:\n",
    "\n",
    "ord_2\n",
    "\n",
    "| Index | Feature \n",
    "| --- | --- | \n",
    "| 0 | Warm |\n",
    "| 1 | Hot  |\n",
    "| 2 | Lava hot |\n",
    "\n",
    "\n",
    "Currently, we are looking at only three samples in the daatset. Let's convert this to binary representation where we have three for each sample.\n",
    "\n",
    "These three items are the three features.\n",
    "\n",
    "| Index | Feature_0 | Feature_1 | Feature_2\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | 0 | 0 | 1 |\n",
    "| 1 | 1 | 0 | 0 |\n",
    "| 2 | 1 | 0 | 1 |\n",
    "\n",
    "\n",
    "So, our feature are stored in a matrix which has 3 rows and 3 columns. Each element of matrix occupies 8 bytes. So, our total memory requirement for this array is 8x3x3 = 72 bytes\n",
    "\n",
    "We can also check this using python snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "#create our example feature matrix \n",
    "example = np.array( [ [0, 0, 1], [1, 0, 0], [1, 0, 1] ] ) \n",
    "\n",
    "#print size in bytes \n",
    "\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before we are only interested in 1s. 0s are not that important because anything multiplied with 0 will be zero and 0 added/subtracted to/from anything doesn’t make any difference. One way to represent this matrix only with ones would be some kind of dictionary method in which keys are indices of rows and columns and value is 1:\n",
    "\n",
    "* (0, 2) 1 \n",
    "* (1, 0) 1 \n",
    "* (2, 0) 1 \n",
    "* (2, 2) 1 \n",
    "\n",
    "The total memory used will be 8x4 = 32 bytes.\n",
    "\n",
    "Any numpy array can be converted to a sparse matrix by simple python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse \n",
    "\n",
    "\n",
    "#create our example feature matrix\n",
    "\n",
    "example = np.array(\n",
    "    [\n",
    "     [0,0,1],\n",
    "     [1,0,0],\n",
    "     [1,0,1]   \n",
    "    ]\n",
    ")\n",
    "\n",
    "# convert numpy array to saprse CSR matrix \n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "\n",
    "#print size of this sparse matrix \n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total size of the sparse csr matrix is the sum of three values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sparse_example.data.nbytes + \n",
    "    sparse_example.indptr.nbytes + \n",
    "    sparse_example.indices.nbytes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the sparse representation of binarized features takes much less memory than its dense representation, there is another transformation for categorical variable that takes even less memory. That is known as **One Hot Encoding.**\n",
    "\n",
    "One hot encoding is a binary encoding too in the sense that there are only two values, 0s and 1s. However, it must be noted that it’s not a binary representation. Its representation can be understood by looking at the following example. \n",
    "\n",
    "Suppose we represent each category of the ord_2 variable by a vector. This vector is of the same size as the number of categories in the ord_2 variable. In this specific case, each vector is of size six and has all zeros except at one position. Let’s look at this particular table of vectors. \n",
    "\n",
    "|  |  |  |  |  |  |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| Freezing | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "| Warm | 0 | 0 | 0 | 0 | 1 | 0 |\n",
    "| Cold | 0 | 0 | 0 | 1 | 0 | 0 |\n",
    "| Boiling Hot | 0 | 0 | 1 | 0 | 0 | 0 | \n",
    "| Hot | 0 | 1 | 0 | 0 | 0 | 0 |\n",
    "| Lava Hot | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "\n",
    "We see that the size of vectors is 1x6, i.e. there are six elements in the vector. Where does this number come from? If you look carefully, you will see that there are six categories, as mentioned before. When one-hot encoding, the vector size has to be same as the number of categories we are looking at. Each vector has a 1 and rest all other values are 0s. Now, let’s use these features instead of the binarized feature as before and see how much memory can we save. \n",
    "\n",
    "\n",
    "If you remember the old data, it looked as follows:\n",
    "\n",
    "\n",
    "| Index | Feature |\n",
    "| --- | --- |\n",
    "| 0 | Warm |\n",
    "| 1 | Hot | \n",
    "| 2 | Lava Hot | \n",
    "\n",
    "And we had three feature for each sample. But one-hot vector in this case are size 6. Thus we have 6 feature instead of 3.\n",
    "\n",
    "| Index  | F_0  | F_1  | F_2  | F_3 | F_4  | F_5 |\n",
    "| --- | --- | --- | --- | --- | --- | --- |   \n",
    "| 0 | 0 | 0 | 0 | 0 | 1 | 0 |\n",
    "| 1 | 0 | 1 | 0 | 0 | 0 | 0 |\n",
    "| 2 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 144\n",
      "Size of sparse array: 24\n",
      "Full size of sparse array: 52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy import sparse \n",
    "\n",
    "#create binary matrix \n",
    "example = np.array( [ [0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0] ] ) \n",
    "\n",
    "#print size in bytes \n",
    "\n",
    "print(f\"Size of dense array: {example.nbytes}\") \n",
    "\n",
    "#convert numpy array to sparse CSR matrix \n",
    "sparse_example = sparse.csr_matrix(example) \n",
    "\n",
    "#print size of this sparse matrix \n",
    "\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\") \n",
    "\n",
    "full_size = ( sparse_example.data.nbytes + sparse_example.indptr.nbytes + sparse_example.indices.nbytes ) \n",
    "#print full size of this sparse matrix \n",
    "print(f\"Full size of sparse array: {full_size}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can see that the size of the parse matrix for one-hot encoding is small as compare to the size of the sparse matrix for binarization.\n",
    "\n",
    "The difference is more noteable when we take a data of much bigger size.\n",
    "\n",
    "\n",
    "\n",
    "* These three methods are the most important ways to handle categorical variables. \n",
    "* There are, however, many other different methods you can use to handle categorical variables. \n",
    "* An example of one such method is about converting categorical variables to numerical variables. \n",
    "* Suppose we go back to the categorical features dataframe (original cat-in-the-datii) that we had. How many ids do we have in the dataframe where the value of ord_2 is Boiling Hot? We can easily calculate this value by calculating the shape of the dataframe where ord_2 column has the value Boiling Hot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84790, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data \n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df[df.ord_2 == \"Boiling Hot\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 84790 rows which have Boiling Hot as value. We can calculate number for other categories also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Boiling Hot     84790\n",
       "Cold            97822\n",
       "Freezing       142726\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Warm           124239\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just replace ord_2 column with it's count value. This way we can convert it into numerical form.\n",
    "\n",
    "We can either : \n",
    "* Replace that column by using transform\n",
    "* or create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          67508.0\n",
       "1         124239.0\n",
       "2         142726.0\n",
       "3          64840.0\n",
       "4          97822.0\n",
       "            ...   \n",
       "599995    142726.0\n",
       "599996     84790.0\n",
       "599997    142726.0\n",
       "599998    124239.0\n",
       "599999     84790.0\n",
       "Name: id, Length: 600000, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].transform(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add counts of all the features or can also replace them or maybe group by multiple columns and their counts. For example, the following code counts by grouping on ord_1 and ord_2 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>15634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Cold</td>\n",
       "      <td>17734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>26082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>12428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Warm</td>\n",
       "      <td>22774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>19477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Cold</td>\n",
       "      <td>22956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>33249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Hot</td>\n",
       "      <td>15792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Warm</td>\n",
       "      <td>28900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>13623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>15464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>22818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>10805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Master</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Master</td>\n",
       "      <td>Cold</td>\n",
       "      <td>12364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Master</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>18035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master</td>\n",
       "      <td>Hot</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Master</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>15734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Cold</td>\n",
       "      <td>26271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>38233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Hot</td>\n",
       "      <td>17850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>17373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Warm</td>\n",
       "      <td>33263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_1        ord_2  count\n",
       "0   Contributor  Boiling Hot  15634\n",
       "1   Contributor         Cold  17734\n",
       "2   Contributor     Freezing  26082\n",
       "3   Contributor          Hot  12428\n",
       "4   Contributor     Lava Hot  11919\n",
       "5   Contributor         Warm  22774\n",
       "6        Expert  Boiling Hot  19477\n",
       "7        Expert         Cold  22956\n",
       "8        Expert     Freezing  33249\n",
       "9        Expert          Hot  15792\n",
       "10       Expert     Lava Hot  15078\n",
       "11       Expert         Warm  28900\n",
       "12  Grandmaster  Boiling Hot  13623\n",
       "13  Grandmaster         Cold  15464\n",
       "14  Grandmaster     Freezing  22818\n",
       "15  Grandmaster          Hot  10805\n",
       "16  Grandmaster     Lava Hot  10363\n",
       "17  Grandmaster         Warm  19899\n",
       "18       Master  Boiling Hot  10800\n",
       "19       Master         Cold  12364\n",
       "20       Master     Freezing  18035\n",
       "21       Master          Hot   8594\n",
       "22       Master     Lava Hot   8209\n",
       "23       Master         Warm  15734\n",
       "24       Novice  Boiling Hot  22718\n",
       "25       Novice         Cold  26271\n",
       "26       Novice     Freezing  38233\n",
       "27       Novice          Hot  17850\n",
       "28       Novice     Lava Hot  17373\n",
       "29       Novice         Warm  33263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data \n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df.groupby([\"ord_1\",\"ord_2\"])[\"id\"].count().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more trick is to *create new feature from these categorical variables.*  example for creating new feature from existing feature is given as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot\n",
       "1                Grandmaster_Warm\n",
       "2                    nan_Freezing\n",
       "3                 Novice_Lava Hot\n",
       "4                Grandmaster_Cold\n",
       "                   ...           \n",
       "599995            Novice_Freezing\n",
       "599996         Novice_Boiling Hot\n",
       "599997       Contributor_Freezing\n",
       "599998                Master_Warm\n",
       "599999    Contributor_Boiling Hot\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"new_feature\"] = (\n",
    "    df.ord_1.astype(str) \n",
    "    + \"_\"\n",
    "    + df.ord_2.astype(str)\n",
    ")\n",
    "\n",
    "df.new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have combined ord_1 and ord_2 by an underscore, and before that, we convert these columns to string types. Note that NaN will also convert to string. But it’s okay. We can also treat NaN as a new category. Thus, we have a new feature which is a combination of these two features. You can also combine more than three columns or four or even more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"new_feature\"],axis = 1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot_c\n",
       "1                Grandmaster_Warm_e\n",
       "2                    nan_Freezing_n\n",
       "3                 Novice_Lava Hot_a\n",
       "4                Grandmaster_Cold_h\n",
       "                    ...            \n",
       "599995            Novice_Freezing_a\n",
       "599996         Novice_Boiling Hot_n\n",
       "599997       Contributor_Freezing_n\n",
       "599998                Master_Warm_m\n",
       "599999    Contributor_Boiling Hot_b\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"new_feature\"] = (df.ord_1.astype(str)  + \"_\" + df.ord_2.astype(str) + \"_\"  + df.ord_3.astype(str) ) \n",
    "df.new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So which categories should we combine? Well, there isn't an easy answer to that. It depends on your data and the types of features. Some domain knowledge might be useful for creating features like this. But if you don’t have concerns about memory and CPU usage, you can go for a greedy approach where you can create many such combinations and then use a model to decide which features are useful and keep them. \n",
    "\n",
    "Whenever you get categorical variables, follow these simple steps: \n",
    "* fill the NaN values (this is very important!) \n",
    "* convert them to integers by applying label encoding using LabelEncoder of scikit-learn or by using a mapping dictionary. If you didn’t fill up NaN values with something, you might have to take care of them in this step\n",
    "* create onr-hot encoding. Yes , you can skip binarization.\n",
    "* go for the modeling! i mean the machine learning one . Not the ramp.\n",
    "\n",
    "Handling NaN value is quite imp and if your did'nt handle it then during scikit-learn's LabelEncoder you will get the error.\n",
    "\n",
    "**ValueError : y contains previously unseen labels : [nan, nan]**\n",
    "\n",
    "This means when you are transforming the test data, you have nan value in it and you forget to handle those nan value during training process. \n",
    "\n",
    "One simple way to handle nan value is to \n",
    "\n",
    "* **drop them** But it is not a good idea. Cause if there is lot of nan value in the data then by dropping it youa re lossing lot of information which is not a good thing to do.\n",
    "\n",
    "* Another way to handle nan value is to treat them as new category. This the most preferred way of handling nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling NaN value it becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 18075 NaN values which we did'nt consider before.\n",
    "* With the addition of new category the total number of category are now 7 which was previously 6.\n",
    "* This is helpful cause now when we bulit a model we will also going to consider nan value. The more relevant information we have the better our model will perform.\n",
    "\n",
    "* Let’s assume that ord_2 did not have any NaN values. We see that all categories in this column have a significant count. There are no “rare” categories; i.e. the categories which appear only a small percentage of the total number of samples. Now, let’s assume that you have deployed this model which uses this column in production and when the model or the project is live, you get a category in ord_2 column that is not present in train. You model pipeline, in this case, will throw an error and there is nothing that you can do about it. If this happens, then probably something is wrong with your pipeline in production. If this is expected, then you must modify your model pipeline and include a new category to these six categories.\n",
    "\n",
    "* This new category is known as the “rare” category. A rare category is a category which is not seen very often and can include many different categories. You can also try to “predict” the unknown category by using a nearest neighbour model. Remember, if you predict this category, it will become one of the categories from the training data. \n",
    "\n",
    "<img src=\"img1.jpeg\">\n",
    "\n",
    "\n",
    "* When we have a dataset like as shown in figure 3, we can build a simple model that’s trained on all features except “f3”. Thus, you will be creating a model that predicts “f3” when it’s not known or not available in training. \n",
    "\n",
    "* If you have a fixed test set, you can add your test data to training to know about the categories in a given feature. This is very similar to semi-supervised learning in which you use data which is not available for training to improve your model. This will also take care of rare values that appear very less number of times in training data but are in abundance in test data. Your model will be more robust. \n",
    "\n",
    "* Many people think that this idea overfits. It may or may not overfit. There is a simple fix for that. If you design your cross-validation in such a way that it replicates the prediction process when you run your model on test data, then it’s never going to overfit. It means that the first step should be the separation of folds, and in each fold, you should apply the same pre-processing that you want to apply to test data. Suppose you want to concatenate training and test data, then in each fold you must concatenate training and validation data and also make sure that your validation dataset replicates the test set. In this specific case, you must design your validation sets in such a way that it has categories which are “unseen” in the training set. Figure 4: A simple concatenation of training and test sets to learn about the categories\n",
    "\n",
    "<img src=\"img2.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import preprocessing \n",
    "\n",
    "#read training data \n",
    "train = pd.read_csv(\"train.csv\") \n",
    "\n",
    "#read test data \n",
    "test = pd.read_csv(\"test.csv\") \n",
    "\n",
    "#create a fake target column for test data \n",
    "#since this column doesn't exist \n",
    "test.loc[:, \"target\"] = -1 \n",
    "\n",
    "#concatenate both training and test data \n",
    "data = pd.concat([train, test]).reset_index(drop=True) \n",
    "\n",
    "\n",
    "#make a list of features we are interested in \n",
    "#id and target is something we should not encode \n",
    "features = [x for x in train.columns if x not in [\"id\", \"target\"]] \n",
    "\n",
    "#loop over the features list \n",
    "\n",
    "for feat in features:\n",
    "    \n",
    "    #create a new instance of LabelEncoder for each feature \n",
    "    lbl_enc = preprocessing.LabelEncoder() \n",
    "    \n",
    "    #note the trick here \n",
    "    #since its categorical data, we fillna with a string \n",
    "    #and we convert all the data to string type \n",
    "    #so, no matter its int or float, its converted to string \n",
    "    #int/float but categorical!!! \n",
    "    \n",
    "    temp_col = data[feat].fillna(\"NONE\").astype(str).values \n",
    "    \n",
    "    #we can use fit_transform here as we do not \n",
    "    #have any extra test data that we need to \n",
    "    #transform on separately \n",
    "    \n",
    "    data.loc[:, feat] = lbl_enc.fit_transform(temp_col) \n",
    "    \n",
    "    #split the training and test data again \n",
    "    \n",
    "    train = data[data.target != -1].reset_index(drop=True) \n",
    "    test = data[data.target == -1].reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>151</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1400</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2168</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1748</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  ...  \\\n",
       "0   0      0      0      0      0      0      3      5      3      6  ...   \n",
       "1   1      1      1      0      0      2      3      4      0      5  ...   \n",
       "2   2      0      1      0      0      0      3      1      3      0  ...   \n",
       "3   3      2      0      0      0      0      3      0      3      3  ...   \n",
       "4   4      0      2      0      2      0      3      6      3      2  ...   \n",
       "\n",
       "   nom_9  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day  month  target  \n",
       "0     27      2      0      3      3     21     57    5      5       0  \n",
       "1   2113      2      2      6      5     24    151    6      9       0  \n",
       "2   1400      2      4      2     14     16    106    4     11       0  \n",
       "3   2168      0      5      4      1      2     46    2      5       0  \n",
       "4   1748      2      2      1      8      2     51    4      3       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2197</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  ...  \\\n",
       "0  600000      0      0      0      0      2      0      2      0      3  ...   \n",
       "1  600001      0      0      0      0      2      3      0      4      6  ...   \n",
       "2  600002      0      0      0      0      2      0      0      0      6  ...   \n",
       "3  600003      1      0      0      0      0      3      2      0      2  ...   \n",
       "4  600004      0      0      1      0      2      3      0      5      3  ...   \n",
       "\n",
       "   nom_9  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day  month  target  \n",
       "0   2197      2      5      0      6     21    147    2     11      -1  \n",
       "1   1107      0      5      1     14     13     46    1     10      -1  \n",
       "2    812      0      1      6      9     13     12    1      8      -1  \n",
       "3    996      0      1      3     13      1      0    0      8      -1  \n",
       "4    371      0      0      4     15      9     14    2      5      -1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trick works when we have a problem wherre we already know the test dataset.\n",
    "\n",
    "In our case cat-in-the-dat datset we already have unknowns in ord_2 colmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can treat “NONE” as unknown. So, if during live testing, we get new categories that we have not seen before, we will mark them as “NONE”. \n",
    "\n",
    "* This is very similar to natural language processing problems. We always build a model based on a fixed vocabulary. Increasing the size of the vocabulary increases the size of the model. Transformer models like BERT are trained on ~30000 words (for English). So, when we have a new word coming in, we mark it as UNK (unknown). \n",
    "\n",
    "* So, you can either assume that your test data will have the same categories as training or you can introduce a rare or unknown category to training to take care of new categories in test data. Let’s see the value counts in ord_4 column after filling NaN values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that some values appear only a couple thousand times, and some appear almost 40000 times. NaNs are also seen a lot.\n",
    "\n",
    "* We can now define our criteria for calling a value “rare”. Let’s say the requirement for a value being rare in this column is a count of less than 2000. So, it seems, J and L can be marked as rare values. With pandas, it is quite easy to replace categories based on count threshold. Let’s take a look at how it’s done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4 = df.ord_4.fillna(\"NONE\")\n",
    "df.loc[\n",
    "    df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000,\n",
    "    \"ord_4\"\n",
    "] = \"RARE\"\n",
    "\n",
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when it come to test dataset. All the new and unseen categories will be mapped to \"RARE\" and all the missing value will be mapped to \"NONE\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
